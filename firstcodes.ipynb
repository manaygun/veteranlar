{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "# Import numpy\n",
    "import numpy as np\n",
    "# Import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# Import seaborn\n",
    "import seaborn as sn\n",
    "# Import stats\n",
    "from scipy import stats\n",
    "# Import ttest_ind\n",
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset\n",
    "df = pd.read_csv(\"/Users/suleymanaygun/Desktop/untitled folder/train.csv\", header= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the max shown columns to unlimited\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of missing values in each column of the df\n",
    "null_percentage = df.isnull().sum() / len(df)\n",
    "\n",
    "# Identify all the columns where the percentage of missing values is greater than 49%\n",
    "null_cols = null_percentage[null_percentage > 0.49].index.tolist()\n",
    "\n",
    "# Drop all the columns identified in the previous step from the df:\n",
    "df = df.drop(null_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column & Row numbers\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of missing values in each row of the df\n",
    "null_percentage = df.isnull().sum(axis=1) / len(df.columns)\n",
    "\n",
    "# Identify all the rows where the percentage of missing values is greater than 49%\n",
    "null_rows = null_percentage[null_percentage > 0.49].index.tolist()\n",
    "\n",
    "# Drop all the rows identified in the previous step from the df:\n",
    "df = df.drop(null_rows, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column & Row numbers\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.boxplot(df[70])\n",
    "\n",
    "# set axis labels and title\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.title('Boxplot of Column 70')\n",
    "\n",
    "# show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_threshold = 3\n",
    "# Loop through each column\n",
    "for column in df.columns:\n",
    "    # Check if the column is numerical\n",
    "    if pd.api.types.is_numeric_dtype(df[column]):\n",
    "        # Calculate the z-score for each data point in the column\n",
    "        z_scores = np.abs(stats.zscore(df[column]))\n",
    "        # Replace outliers with null values\n",
    "        df[column][z_scores > z_threshold] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of types of data types in a column\n",
    "\n",
    "df[45].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution percentages of types of data types in a column\n",
    "\n",
    "df[45].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect the null values for each column and distribute the null values to existing values according to their ratio:\n",
    "for col_dist in df.columns:\n",
    "    null_indices = df[col_dist].isnull()\n",
    "    fill_values = df[col_dist].value_counts(normalize=True)\n",
    "    df.loc[null_indices, col_dist] = np.random.choice(fill_values.index, size=null_indices.sum(), p=fill_values.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the row is there are more than 95% same value:\n",
    "for col in df.columns:\n",
    "    frequencies = df[col].value_counts()\n",
    "    topfreq = frequencies.iloc[0]\n",
    "    sum = len(df[col])\n",
    "    similarity = topfreq / sum\n",
    "    threshold = 0.95\n",
    "    if similarity > threshold:\n",
    "        df = df.drop(columns=[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign these column names to veteran\n",
    "veteran.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veteran.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remowing the outliers and add mean of the column\n",
    "\n",
    "for col in veteran.columns:\n",
    "  if veteran[col].dtype == 'int64' or veteran[col].dtype == 'float64':\n",
    "    Q1 = veteran[col].quantile(0.25)\n",
    "    Q3 = veteran[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    alt = Q1 - 1.5*IQR\n",
    "    ust = Q3 + 1.5*IQR\n",
    "    train = veteran.loc[(veteran[col] >= alt) & (veteran[col] <= ust)]\n",
    "    mean = veteran[col].mean()\n",
    "    veteran[col].fillna(mean, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It shows if there is any outlier\n",
    "\n",
    "for col in veteran.columns:\n",
    "  if veteran[col].dtype == 'int64' or veteran[col].dtype == 'float64':\n",
    "    Q1 = veteran[col].quantile(0.25)\n",
    "    Q3 = veteran[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    alt_sinir = Q1 - 1.5 * IQR\n",
    "    ust_sinir = Q3 + 1.5 * IQR\n",
    "\n",
    "\n",
    "    outlierlar = veteran.loc[(veteran[col] < alt_sinir) | (veteran[col] > ust_sinir)]\n",
    "\n",
    "    if not outlierlar.empty:\n",
    "        print(f\"{col} sÃ¼tununda {outlierlar.shape[0]} adet outlier var.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veteran.to_csv('veteran.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It deletes the column if the frequency is more than 90%\n",
    "for col in veteran.columns:\n",
    "  frequencies = veteran[col].value_counts()\n",
    "  topfreq = frequencies.iloc[0]\n",
    "  sum = len(veteran[col])\n",
    "  oran = topfreq / sum\n",
    "  esik = 0.98\n",
    "  if oran > esik:\n",
    "    veteran.drop(columns=[col], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veteran[2] = veteran[2].replace({'Y': 1, 'N': 0})\n",
    "veteran[23] = veteran[23].replace({'Y': 1, 'N': 0})\n",
    "veteran[32] = veteran[32].replace({'M': 1, 'F': 0})\n",
    "\n",
    "veteran.to_csv('veteran.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Row number of updated CSV file\n",
    "print(veteran.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column number of updated CSV file\n",
    "print(veteran.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veteran.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentages of data types of a column\n",
    "veteran[58].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veteran[58].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect the null values for each column and distribute the null values to existing values according to their ratio:\n",
    "for col_dist in veteran.columns:\n",
    "    null_indices = veteran[col_dist].isnull()\n",
    "    fill_values = veteran[col_dist].value_counts(normalize=True)\n",
    "    veteran.loc[null_indices, col_dist] = np.random.choice(fill_values.index, size=null_indices.sum(), p=fill_values.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the percentages. If values are between 0 and 1: float, if not: int\n",
    "for column in veteran.columns:\n",
    "    if veteran[column].dtype == 'int64' or veteran[column].dtype == 'float64':\n",
    "\n",
    "    # count the number of values in the column that are between 0 and 1\n",
    "    count = ((veteran[column] > 0) & (veteran[column] < 1)).sum()\n",
    "\n",
    "    # if the majority of values are between 0 and 1, convert the column to float\n",
    "    if count > len(veteran[column]) / 2:\n",
    "        veteran[column] = veteran[column].astype(float)\n",
    "    else:\n",
    "        veteran[column] = veteran[column].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counts null values of the column\n",
    "for count in veteran.columns:\n",
    "    print(veteran[count].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing the strings into numbers\n",
    "veteran[2] = veteran[2].replace({'Y': 1, 'N': 0})\n",
    "veteran[4] = veteran[4].replace({'Panl': 0, 'Stok': 1,'Blok': 2,'Woon': 3,'Mixd': 4,'Monc': 5,'Oths': 6})\n",
    "veteran[8] = veteran[8].replace({'Yes': 1, 'No': 0})\n",
    "veteran[10] = veteran[10].replace({'Unad': 0, 'Famy': 1,'Spor': 2,'Chin': 3,'OthB': 4,'OthA': 5,'Groe': 6})\n",
    "veteran[14] = veteran[14].replace({'Yes': 1, 'No': 0})\n",
    "veteran[16] = veteran[16].replace({'Unad': 0, 'Famy': 1,'Spor': 2,'Chin': 3,'OthB': 4,'OthA': 5,'Groe': 6})\n",
    "veteran[20] = veteran[20].replace({'Worg': 0, 'Come': 1,'Penr': 2,'Stat': 3,'Uned': 4,'Stut': 5,'Busn': 6,'Mate': 7})\n",
    "veteran[21] = veteran[21].replace({'Hout': 0, 'Wits': 1,'Munt': 2,'Rent': 3,'Offt': 4,'Co-t': 5})\n",
    "veteran[32] = veteran[32].replace({'Y': 1, 'N': 0})\n",
    "veteran[44] = veteran[44].replace({'Secl': 0, 'Hign': 1,'Incr': 2,'Lowy': 3,'Acae': 4})\n",
    "veteran[45] = veteran[45].replace({'M': 1, 'F': 0, 'XNA': 0})\n",
    "veteran[47] = veteran[47].replace({'Y': 1, 'N': 0})\n",
    "veteran[58] = veteran[58].replace({'MONY': 0, 'TUEY': 1,'WEDY': 2,'THUY': 3,'FRIY': 4,'SATY': 5,'SUNY': 6})\n",
    "veteran[64] = veteran[64].replace({'Cass': 1, 'Revs': 0})\n",
    "veteran[67] = veteran[67].replace({'Secl': 0, 'Hign': 1,'Incr': 2,'Lowy': 3,'Acae': 4})\n",
    "veteran[69] = veteran[69].replace({'M': 1, 'F': 0})\n",
    "veteran[74] = veteran[74].replace({'Mard': 0, 'Sind': 1,'Cive': 2,'Sepd': 3,'Widw': 4,'Unkn': 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the column type to float\n",
    "veteran[17] = veteran[17].astype(float)\n",
    "veteran[23] = veteran[23].astype(float)\n",
    "veteran[24] = veteran[24].astype(float)\n",
    "veteran[48] = veteran[48].astype(float)\n",
    "veteran[54] = veteran[54].astype(float)\n",
    "veteran[55] = veteran[55].astype(float)\n",
    "veteran[57] = veteran[57].astype(float)\n",
    "veteran[69] = veteran[69].astype(float)\n",
    "veteran[70] = veteran[70].astype(float)\n",
    "veteran[72] = veteran[72].astype(float)\n",
    "veteran[75] = veteran[75].astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the column type to integer\n",
    "veteran[17] = veteran[17].astype(int)\n",
    "veteran[23] = veteran[23].astype(int)\n",
    "veteran[24] = veteran[24].astype(int)\n",
    "veteran[48] = veteran[48].astype(int)\n",
    "veteran[54] = veteran[54].astype(int)\n",
    "veteran[55] = veteran[55].astype(int)\n",
    "veteran[57] = veteran[57].astype(int)\n",
    "veteran[70] = veteran[70].astype(int)\n",
    "veteran[75] = veteran[75].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decreasing the float numbers to 2 after the comma\n",
    "veteran[[15, 35, 38,52 ,56, 69, 72]] = veteran[[15, 35, 38,52 ,56, 69, 72]].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column types\n",
    "for column in veteran.columns:\n",
    "    print(veteran[column].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace null values with the mean of the columns\n",
    "# veteran = veteran.fillna(veteran.mean())\n",
    "# Decision changed because since we didn't know the meaning of the columns, instead of fill the null values with means, we prefered to fill the nul values with percentage of existing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veteran.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we handled the null values\n",
    "# The percentage of null values in each row\n",
    "   # null_percentage = veteran.isnull().sum(axis=1) / len(veteran.columns)\n",
    "# Row indices that have more than 49% null values\n",
    "   # null_rows = null_percentage[null_percentage > 0.49].index.tolist()\n",
    "# Drop the rows with more than 49% null values\n",
    "   #veteran = veteran.drop(null_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Row and column number of updated CSV file\n",
    "print(veteran.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Details of the columns\n",
    "veteran.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veteran.corr()\n",
    "corr_matrix = veteran.corr()\n",
    "sn.set (rc = {'figure.figsize':(32, 32)})\n",
    "sn.heatmap(corr_matrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veteran.drop(43, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veteran.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veteran.corr()\n",
    "corr_matrix = veteran.corr()\n",
    "sn.set (rc = {'figure.figsize':(32, 32)})\n",
    "sn.heatmap(corr_matrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
