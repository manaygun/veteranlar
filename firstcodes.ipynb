{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "# Import numpy\n",
    "import numpy as np\n",
    "# Import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# Import seaborn\n",
    "import seaborn as sn\n",
    "# Import stats\n",
    "from scipy import stats\n",
    "# Import ttest_ind\n",
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset\n",
    "df = pd.read_csv(\"/Users/suleymanaygun/Desktop/untitled folder/train.csv\", header= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the max shown columns to unlimited\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of missing values in each column of the df\n",
    "null_percentage = df.isnull().sum() / len(df)\n",
    "\n",
    "# Identify all the columns where the percentage of missing values is greater than 49%\n",
    "null_cols = null_percentage[null_percentage > 0.49].index.tolist()\n",
    "\n",
    "# Drop all the columns identified in the previous step from the df:\n",
    "df = df.drop(null_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column & Row numbers\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of missing values in each row of the df\n",
    "null_percentage = df.isnull().sum(axis=1) / len(df.columns)\n",
    "\n",
    "# Identify all the rows where the percentage of missing values is greater than 49%\n",
    "null_rows = null_percentage[null_percentage > 0.49].index.tolist()\n",
    "\n",
    "# Drop all the rows identified in the previous step from the df:\n",
    "df = df.drop(null_rows, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column & Row numbers\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.boxplot(df[70])\n",
    "\n",
    "# set axis labels and title\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.title('Boxplot of Column 70')\n",
    "\n",
    "# show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_threshold = 3\n",
    "# Loop through each column\n",
    "for column in df.columns:\n",
    "    # Check if the column is numerical\n",
    "    if pd.api.types.is_numeric_dtype(df[column]):\n",
    "        # Calculate the z-score for each data point in the column\n",
    "        z_scores = np.abs(stats.zscore(df[column]))\n",
    "        # Replace outliers with null values\n",
    "        df[column][z_scores > z_threshold] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of types of data types in a column\n",
    "\n",
    "df[45].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution percentages of types of data types in a column\n",
    "\n",
    "df[45].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect the null values for each column and distribute the null values to existing values according to their ratio:\n",
    "for col_dist in df.columns:\n",
    "    null_indices = df[col_dist].isnull()\n",
    "    fill_values = df[col_dist].value_counts(normalize=True)\n",
    "    df.loc[null_indices, col_dist] = np.random.choice(fill_values.index, size=null_indices.sum(), p=fill_values.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the row is there are more than 95% same value:\n",
    "for col in df.columns:\n",
    "    frequencies = df[col].value_counts()\n",
    "    topfreq = frequencies.iloc[0]\n",
    "    sum = len(df[col])\n",
    "    similarity = topfreq / sum\n",
    "    threshold = 0.95\n",
    "    if similarity > threshold:\n",
    "        df = df.drop(columns=[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column & Row numbers\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_stat, p_value = ttest_ind(df[9], df[53])\n",
    "\n",
    "if p_value > 0.85 or p_value < -0.85 :\n",
    "    print(\"There is a significant difference in columns.\")\n",
    "else:\n",
    "    print(\"There is no significant difference in columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Map\n",
    "\n",
    "df.corr()\n",
    "corr_matrix = df.corr()\n",
    "sn.set (rc = {'figure.figsize':(30,30)})\n",
    "sn.heatmap(corr_matrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see the relationship between two column\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "plt.scatter(df[80], df[109])\n",
    "plt.xlabel('80')\n",
    "plt.ylabel('109')\n",
    "plt.title('Scatter Plot for 80 and 109 Columns')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns that have higher similarity than 0.78:\n",
    "\n",
    "df.drop(35, axis=1, inplace=True)\n",
    "df.drop(37, axis=1, inplace=True)\n",
    "df.drop(66, axis=1, inplace=True)\n",
    "df.drop(71, axis=1, inplace=True)\n",
    "df.drop(72, axis=1, inplace=True)\n",
    "df.drop(99, axis=1, inplace=True)\n",
    "df.drop(104, axis=1, inplace=True)\n",
    "df.drop(118, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing the strings into numbers\n",
    "df[5] = df[5].replace({'Y': 1, 'N': 0})\n",
    "df[16] = df[16].replace({'Unad': 0, 'Famy': 1,'Spor': 2,'Chin': 3,'OthB': 4,'OthA': 5,'Groe': 6})\n",
    "df[30] = df[30].replace({'Worg': 0, 'Come': 1,'Penr': 2,'Stat': 3,'Uned': 4,'Stut': 5,'Busn': 6,'Mate': 7})\n",
    "df[31] = df[31].replace({'Hout': 0, 'Wits': 1,'Munt': 2,'Rent': 3,'Offt': 4,'Co-t': 5})\n",
    "df[47] = df[47].replace({'Y': 1, 'N': 0})\n",
    "df[67] = df[67].replace({'Secl': 0, 'Hign': 1,'Incr': 2,'Lowy': 3,'Acae': 4})\n",
    "df[69] = df[69].replace({'M': 1, 'F': 0, 'XNA': 0})\n",
    "df[93] = df[93].replace({'MONY': 0, 'TUEY': 1,'WEDY': 2,'THUY': 3,'FRIY': 4,'SATY': 5,'SUNY': 6})\n",
    "df[103] = df[103].replace({'Cass': 1, 'Revs': 0})\n",
    "df[117] = df[117].replace({'Mard': 0, 'Sind': 1,'Cive': 2,'Sepd': 3,'Widw': 4,'Unkn': 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the percentages. If values are between 0 and 1: float, if not: int\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == 'int64' or df[column].dtype == 'float64':\n",
    "\n",
    "    # count the number of values in the column that are between 0 and 1\n",
    "    count = ((df[column] > 0) & (df[column] < 1)).sum()\n",
    "\n",
    "    # if the majority of values are between 0 and 1, convert the column to float\n",
    "    if count > len(df[column]) / 2:\n",
    "        df[column] = df[column].astype(float)\n",
    "    else:\n",
    "        df[column] = df[column].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decreasing the float numbers to 2 after the comma\n",
    "df[[25, 53, 58, 89, 109]] = df[[25, 53, 58, 89, 109]].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Map\n",
    "\n",
    "df.corr()\n",
    "corr_matrix = df.corr()\n",
    "sn.set (rc = {'figure.figsize':(30, 30)})\n",
    "sn.heatmap(corr_matrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new csv file with last version\n",
    "df.to_csv('df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of the column 93\n",
    "# Because we wanted to look at days distribution since we understood that this column was day column\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.hist(df[93], bins=7)\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Days')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a bar chart of the 'Sex' column\n",
    "plt.figure(figsize=(5, 4))\n",
    "sn.countplot(x=69, data=df)\n",
    "plt.xlabel('Sex')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Sex')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
