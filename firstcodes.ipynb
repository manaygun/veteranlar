{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "# Import numpy\n",
    "import numpy as np\n",
    "# Import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# Import seaborn\n",
    "import seaborn as sn\n",
    "# Import stats\n",
    "from scipy import stats\n",
    "# Import ttest_ind\n",
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file\n",
    "veteran = pd.read_csv(\"/Users/suleymanaygun/Desktop/untitled folder/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The percentage of null values in each column\n",
    "null_percentage = veteran.isnull().sum() / len(veteran)\n",
    "# Column names that have more than 49% null values\n",
    "null_cols = null_percentage[null_percentage > 0.49].index.tolist()\n",
    "# Drop the columns with more than 49% null values\n",
    "veteran = veteran.drop(null_cols, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the updated CSV file\n",
    "veteran = pd.read_csv(\"/Users/zülal/Desktop/GIITHUB4/veteranv1.csv\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The percentage of null values in each row\n",
    "null_percentage = veteran.isnull().sum(axis=1) / len(veteran.columns)\n",
    "# Row indices that have more than 49% null values\n",
    "null_rows = null_percentage[null_percentage > 0.49].index.tolist()\n",
    "# Drop the rows with more than 49% null values\n",
    "veteran = veteran.drop(null_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Row number of updated CSV file\n",
    "print(veteran.shape[0])\n",
    "# Column number of updated CSV file\n",
    "print(veteran.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "veteran.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veteran.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(veteran.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veteran['0.1613'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(veteran[\"0.1613\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In [122]: veteran.isnull().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veteran.v1 = veteran.dropna(thresh=3000000000, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veteran.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veteran.describe()[\"0.1613\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veteran = pd.read_csv(\"/content/drive/MyDrive/mis208dataset/train.csv\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veteran.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random column names\n",
    "import random\n",
    "import string\n",
    "\n",
    "num_cols = 78\n",
    "col_length = 5\n",
    "columns = []\n",
    "\n",
    "for i in range(num_cols):\n",
    "    col_name = ''.join(random.choices(string.ascii_uppercase, k=col_length))\n",
    "    columns.append(col_name)\n",
    "\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign these column names to veteran\n",
    "veteran.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_veteran = veteran.sort_values(by='YLTAM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_veteran.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we know that the first column is refer to a ID, with this command it deletes the duplicated rows\n",
    "veteran.drop_duplicates(subset=['CRCDD'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remowing the outliers and add mean of the column\n",
    "\n",
    "for col in veteranv3.columns:\n",
    "  if veteranv3[col].dtype == 'int64' or veteranv3[col].dtype == 'float64':\n",
    "    Q1 = veteranv3[col].quantile(0.25)\n",
    "    Q3 = veteranv3[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    alt = Q1 - 1.5*IQR\n",
    "    ust = Q3 + 1.5*IQR\n",
    "    train = veteranv3.loc[(veteranv3[col] >= alt) & (veteranv3[col] <= ust)]\n",
    "    mean = veteranv3[col].mean()\n",
    "    veteranv3[col].fillna(mean, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It shows if there is any outlier\n",
    "\n",
    "for col in veteranv3.columns:\n",
    "  if veteranv3[col].dtype == 'int64' or veteranv3[col].dtype == 'float64':\n",
    "    Q1 = veteranv3[col].quantile(0.25)\n",
    "    Q3 = veteranv3[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    alt_sinir = Q1 - 1.5 * IQR\n",
    "    ust_sinir = Q3 + 1.5 * IQR\n",
    "\n",
    "\n",
    "    outlierlar = veteranv3.loc[(veteranv3[col] < alt_sinir) | (veteranv3[col] > ust_sinir)]\n",
    "\n",
    "    if not outlierlar.empty:\n",
    "        print(f\"{col} sütununda {outlierlar.shape[0]} adet outlier var.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veteran.to_csv('veteranv2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deletion of row\n",
    "veteranv6 = veteranv6.drop([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It deletes the column if the frequency is more than 90%\n",
    "for col in veteranv5.columns:\n",
    "  frequencies = veteranv5[col].value_counts()\n",
    "  topfreq = frequencies.iloc[0]\n",
    "  sum = len(veteranv5[col])\n",
    "  oran = topfreq / sum\n",
    "  esik = 0.9\n",
    "  if oran > esik:\n",
    "    veteranv5.drop(columns=[col], inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
